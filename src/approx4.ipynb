{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_return_vkco</th>\n",
       "      <th>log_return_tcs_il</th>\n",
       "      <th>log_return_poly_il</th>\n",
       "      <th>log_return_five_il</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.012110</td>\n",
       "      <td>-0.004162</td>\n",
       "      <td>-0.003712</td>\n",
       "      <td>-0.013377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.035292</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.029352</td>\n",
       "      <td>-0.024070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.011583</td>\n",
       "      <td>0.002083</td>\n",
       "      <td>-0.013279</td>\n",
       "      <td>0.007894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.006740</td>\n",
       "      <td>0.004154</td>\n",
       "      <td>0.025964</td>\n",
       "      <td>-0.002916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.009709</td>\n",
       "      <td>0.015425</td>\n",
       "      <td>-0.010984</td>\n",
       "      <td>-0.007034</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-0.007648</td>\n",
       "      <td>0.018653</td>\n",
       "      <td>0.030041</td>\n",
       "      <td>0.010193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.019012</td>\n",
       "      <td>0.044184</td>\n",
       "      <td>0.029452</td>\n",
       "      <td>-0.006216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.018657</td>\n",
       "      <td>0.038540</td>\n",
       "      <td>0.008584</td>\n",
       "      <td>0.036732</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.046940</td>\n",
       "      <td>0.035287</td>\n",
       "      <td>0.042393</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>0.020943</td>\n",
       "      <td>0.012693</td>\n",
       "      <td>0.028269</td>\n",
       "      <td>0.003818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     log_return_vkco  log_return_tcs_il  log_return_poly_il  \\\n",
       "0          -0.012110          -0.004162           -0.003712   \n",
       "1          -0.035292           0.000000           -0.029352   \n",
       "2           0.011583           0.002083           -0.013279   \n",
       "3          -0.006740           0.004154            0.025964   \n",
       "4          -0.009709           0.015425           -0.010984   \n",
       "..               ...                ...                 ...   \n",
       "248        -0.007648           0.018653            0.030041   \n",
       "249         0.019012           0.044184            0.029452   \n",
       "250         0.018657           0.038540            0.008584   \n",
       "251         0.046940           0.035287            0.042393   \n",
       "252         0.020943           0.012693            0.028269   \n",
       "\n",
       "     log_return_five_il  \n",
       "0             -0.013377  \n",
       "1             -0.024070  \n",
       "2              0.007894  \n",
       "3             -0.002916  \n",
       "4             -0.007034  \n",
       "..                  ...  \n",
       "248            0.010193  \n",
       "249           -0.006216  \n",
       "250            0.036732  \n",
       "251            0.000000  \n",
       "252            0.003818  \n",
       "\n",
       "[253 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from numpy import array, exp \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt \n",
    "import openturns as ot\n",
    "from scipy.optimize import curve_fit \n",
    "from scipy.stats import genhyperbolic\n",
    "from scipy.stats import levy_stable\n",
    "from scipy.stats import norm\n",
    "from scipy.stats import cumfreq\n",
    "from scipy.stats import kstest\n",
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import cramervonmises_2samp\n",
    "from scipy.stats import anderson_ksamp\n",
    "\n",
    "dataset = pd.read_csv(\"../data/log_return_data.csv\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Делим интервал значений случ. вел на bins подинтервалов. Вычисляем количество попаданий в эти подинтервалы\n",
    "#Фактически имитируем набор данных для plot.hist()\n",
    "def get_intervals(dataframe, column, bins):\n",
    "    intervals = []\n",
    "    data = dataframe[column]\n",
    "    ln = len(data)\n",
    "    max_value = max(data)\n",
    "    min_value = min(data)\n",
    "    interval_length = (max_value - min_value)\n",
    "    for i in range(0, bins):\n",
    "        s = 0\n",
    "        a = min_value + (i)*interval_length/bins\n",
    "        b = min_value + (i+1)*interval_length/bins\n",
    "        for k in range(0, len(data)):\n",
    "            if (data[k]>= a and data[k]<b):\n",
    "                s = s + 1\n",
    "        #intervals.append(s/(ln-1))\n",
    "        intervals.append(s)\n",
    "    x_interavals = np.arange(min_value, max_value, abs(max_value- min_value)/bins)\n",
    "    return intervals, x_interavals, min_value, max_value\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rvs_intervals(data, bins, x_data):\n",
    "    intervals = []\n",
    "    max_value = max(x_data)\n",
    "    min_value = min(x_data)\n",
    "    interval_length = (max_value - min_value)\n",
    "    for i in range(0, bins):\n",
    "        s = 0\n",
    "        a = min_value + (i)*interval_length/bins\n",
    "        b = min_value + (i+1)*interval_length/bins\n",
    "        for k in range(0, len(data)):\n",
    "            if (data[k]>= a and data[k]<b):\n",
    "                s = s + 1\n",
    "        intervals.append(s)\n",
    "    norm_intervals = [x/sum(intervals) for x in intervals]\n",
    "    return norm_intervals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определяем приближающую функцию - Нормальное распределение\n",
    "def norm_mapping(values_x, a, b): \n",
    "    #return 1/(math.sqrt(2*math.pi)*b) * exp(-1/2*((values_x-a)/b)**2)\n",
    "    return norm.pdf(values_x,a,b)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определяем приближающую функцию - Гиперболическое распределение\n",
    "def hyper_mapping(values_x, p, a, b, mu, delta):\n",
    "    #genhyperbolic.pdf(x, p, a, b, loc, scale)  scale = delta, loc = mu, p = lambda, a = alpha delta, b = beta delta\n",
    "    if (a>b):\n",
    "        return genhyperbolic.pdf(values_x, p, a, b, mu, delta)\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определяем приближающую функцию - Устойчивое распределение\n",
    "def stable_mapping(values_x, alpha, beta, gamma, mu):\n",
    "    return levy_stable.pdf(values_x, alpha, beta, gamma, mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Определяем приближающую функцию - Устойчивое распределение\n",
    "def stable_mapping(values_x, alpha, beta, gamma, mu):\n",
    "    return levy_stable.pdf(values_x, alpha, beta, gamma, mu)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(x, a, b, c, d, e, f):\n",
    "    return a+b*x+c*x**2+d*x**3+e*x**4+f*x**5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_return_five_il\n"
     ]
    }
   ],
   "source": [
    "#Читаем файл с данными\n",
    "dataset = pd.read_csv(\"../data/log_return_data.csv\")\n",
    "\n",
    "#Выполняем обработку исходных данных\n",
    "bins = 25\n",
    "compName = 'log_return_five_il' #'log_return_five_il' log_return_vkco\tlog_return_tcs_il\tlog_return_poly_il gazpr_futures\n",
    "print(compName)\n",
    "readData = get_intervals(dataset, compName, bins)  \n",
    "y_data, x_data, min_value, max_value = readData[0], readData[1], readData[2], readData[3]\n",
    "x_fit = np.arange(min_value, max_value, abs(max_value- min_value)/400)\n",
    "y_data1 = [x/sum(y_data) for x in y_data]\n",
    "\n",
    "#Строим эмпирическую функцию распределения\n",
    "emp_data = cumfreq(dataset[compName], numbins=bins, defaultreallimits=None, weights=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_emp_data(dataframe, columns, bins):\n",
    "    #Выполняем обработку исходных данных\n",
    "    readData = get_intervals(dataset, columns, bins)  \n",
    "    y_data, x_data, min_value, max_value = readData[0], readData[1], readData[2], readData[3]\n",
    "    x_fit = np.arange(min_value, max_value, abs(max_value- min_value)/400)\n",
    "    y_data1 = [x/sum(y_data) for x in y_data]\n",
    "\n",
    "    #Строим эмпирическую функцию распределения\n",
    "    emp_data = cumfreq(dataset[columns], numbins=bins, defaultreallimits=None, weights=None)\n",
    "    return emp_data, y_data1, x_fit, x_data, y_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closer_finding_functions_hyperbolic(x_data, y_data, data, column):\n",
    "    #Производим приближение - Гиперболическое распределение\n",
    "    params, _  = curve_fit(hyper_mapping, x_data, y_data) \n",
    "    p, a, b, mu, delta = params[0], params[1], params[2], params[3], params[4]\n",
    "    y_fit = genhyperbolic.pdf(x_fit, p, a, b, mu, delta) \n",
    "    \n",
    "    #Считаем pvalue - Гиперболическое распределение\n",
    "    r = genhyperbolic.rvs(p, a, b, mu, delta, size=252, random_state=None)\n",
    "    #Выполняем нормировку набора случайных величин\n",
    "    norm_rvs_data = get_rvs_intervals(r, bins, x_data)\n",
    "    norm_rvs_data1 = [x/sum(norm_rvs_data) for x in norm_rvs_data]\n",
    "\n",
    "    return params, r, y_fit, norm_rvs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Производим приближение - Устойчивое распределение\n",
    "def closer_finding_functions_stable(x_data, y_data):\n",
    "    \n",
    "    params, _  = curve_fit(stable_mapping, x_data, y_data, bounds=([1.0001, -1., -1., 0.],[2, 1., 6., 6.])) \n",
    "    # args, _  = curve_fit(stable_mapping, x_data, y_data) \n",
    "    alpha, beta , gamma, mu = params[0], params[1], params[2], params[3]\n",
    "    y_fit = levy_stable.pdf(x_fit, alpha, beta, gamma, mu)\n",
    "\n",
    "    #Считаем pvalue - Устойчивое распределение\n",
    "    r = levy_stable.rvs(alpha, beta, gamma, mu, size=1000, random_state=None)\n",
    "    #Выполняем нормировку набора случайных величин\n",
    "    norm_rvs_data = get_rvs_intervals(r, bins, x_data)\n",
    "    norm_rvs_data = [x/sum(norm_rvs_data) for x in norm_rvs_data]\n",
    "    return params, r, y_fit, norm_rvs_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Производим приближение - Устойчивое распределение\n",
    "def closer_finding_functions_stable(x_data, data, columns):\n",
    "    params = levy_stable._fitstart(data[columns])\n",
    "    alpha, beta , gamma, mu = params[0], params[1], params[2], params[3]\n",
    "\n",
    "    y_fit = levy_stable.pdf(x_fit, alpha, beta, gamma, mu)\n",
    "\n",
    "    #Считаем pvalue - Устойчивое распределение\n",
    "    r = levy_stable.rvs(alpha, beta, gamma, mu, size=252, random_state=None)\n",
    "\n",
    "    #Выполняем нормировку набора случайных величин\n",
    "    norm_rvs_data = get_rvs_intervals(r, bins, x_data)\n",
    "    return params, r, y_fit, norm_rvs_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# #Производим приближение - Распределение Мейснера\n",
    "def closer_finding_functions_meixner(x_data, data, columns):\n",
    "    data1 = [[i] for i in data[columns]]\n",
    "    sample = ot.Sample(data1)\n",
    "    ot.ResourceMap.SetAsUnsignedInteger('DistributionFactory-DefaultBootstrapSize', 253)\n",
    "    fittedRes = ot.MeixnerDistributionFactory().build(sample)\n",
    "    params = fittedRes.getParameter()\n",
    "    alpha, beta , gamma, delta = params[0], params[1], params[2], params[3]\n",
    "    distribution = ot.MeixnerDistribution(alpha, beta , gamma, delta)\n",
    "    y_fit = []\n",
    "    for x in x_fit:\n",
    "        y_fit.append(distribution.computePDF(x))\n",
    "    \n",
    "    sample = ot.MeixnerDistribution(alpha, beta, gamma, delta).getSample(253)\n",
    "    r = sample.asPoint()\n",
    "    norm_rvs_data = get_rvs_intervals(r, bins, x_data)\n",
    "\n",
    "    return params, sample, y_fit, norm_rvs_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Гиперболическое распределение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6140/855056969.py:12: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  p_value_hyperbolic_anderson.append(anderson_ksamp([norm_rvs_hyperbolic, y_data1]).significance_level)\n",
      "/tmp/ipykernel_6140/855056969.py:12: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  p_value_hyperbolic_anderson.append(anderson_ksamp([norm_rvs_hyperbolic, y_data1]).significance_level)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ks_test  anderson  cramervonmises\n",
      "log_return_vkco     0.000082     0.001    3.597120e-06\n",
      "log_return_tcs_il   0.000850     0.001    1.516812e-06\n",
      "log_return_poly_il  0.002353     0.001    7.960949e-06\n",
      "log_return_five_il  0.000125     0.001    3.844349e-07\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6140/855056969.py:12: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  p_value_hyperbolic_anderson.append(anderson_ksamp([norm_rvs_hyperbolic, y_data1]).significance_level)\n",
      "/tmp/ipykernel_6140/855056969.py:12: UserWarning: p-value floored: true value smaller than 0.001\n",
      "  p_value_hyperbolic_anderson.append(anderson_ksamp([norm_rvs_hyperbolic, y_data1]).significance_level)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_return_vkco</th>\n",
       "      <th>log_return_tcs_il</th>\n",
       "      <th>log_return_poly_il</th>\n",
       "      <th>log_return_five_il</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.008503</td>\n",
       "      <td>-0.011504</td>\n",
       "      <td>-0.002174</td>\n",
       "      <td>-0.011678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.008274</td>\n",
       "      <td>-0.018666</td>\n",
       "      <td>-0.019389</td>\n",
       "      <td>-0.013219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.016599</td>\n",
       "      <td>-0.014689</td>\n",
       "      <td>-0.005418</td>\n",
       "      <td>-0.019577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.006595</td>\n",
       "      <td>-0.018371</td>\n",
       "      <td>-0.009205</td>\n",
       "      <td>-0.022388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.007975</td>\n",
       "      <td>-0.009824</td>\n",
       "      <td>-0.008870</td>\n",
       "      <td>-0.029074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>-0.001345</td>\n",
       "      <td>-0.014717</td>\n",
       "      <td>-0.016724</td>\n",
       "      <td>-0.024230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>0.003084</td>\n",
       "      <td>-0.018819</td>\n",
       "      <td>-0.008231</td>\n",
       "      <td>-0.010961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-0.004332</td>\n",
       "      <td>-0.016216</td>\n",
       "      <td>-0.014828</td>\n",
       "      <td>-0.022572</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>-0.022118</td>\n",
       "      <td>-0.019652</td>\n",
       "      <td>-0.010666</td>\n",
       "      <td>-0.016261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>-0.008760</td>\n",
       "      <td>-0.009672</td>\n",
       "      <td>-0.020460</td>\n",
       "      <td>-0.022886</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     log_return_vkco  log_return_tcs_il  log_return_poly_il  \\\n",
       "0          -0.008503          -0.011504           -0.002174   \n",
       "1          -0.008274          -0.018666           -0.019389   \n",
       "2          -0.016599          -0.014689           -0.005418   \n",
       "3          -0.006595          -0.018371           -0.009205   \n",
       "4          -0.007975          -0.009824           -0.008870   \n",
       "..               ...                ...                 ...   \n",
       "247        -0.001345          -0.014717           -0.016724   \n",
       "248         0.003084          -0.018819           -0.008231   \n",
       "249        -0.004332          -0.016216           -0.014828   \n",
       "250        -0.022118          -0.019652           -0.010666   \n",
       "251        -0.008760          -0.009672           -0.020460   \n",
       "\n",
       "     log_return_five_il  \n",
       "0             -0.011678  \n",
       "1             -0.013219  \n",
       "2             -0.019577  \n",
       "3             -0.022388  \n",
       "4             -0.029074  \n",
       "..                  ...  \n",
       "247           -0.024230  \n",
       "248           -0.010961  \n",
       "249           -0.022572  \n",
       "250           -0.016261  \n",
       "251           -0.022886  \n",
       "\n",
       "[252 rows x 4 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value_hyperbolic_kstest = []\n",
    "p_value_hyperbolic_cramervonmises = []\n",
    "p_value_hyperbolic_anderson = []\n",
    "df_hyperbolic_distribution = pd.DataFrame()\n",
    "\n",
    "for column in dataset.columns:\n",
    "    emp_data, y_data1, x_fit, x_data, y_data = get_emp_data(dataset, column, 15)\n",
    "    params_hyperbolic, hyperbolic_distribution, y_fit_hyperbolic, norm_rvs_hyperbolic = closer_finding_functions_hyperbolic(x_data, y_data, dataset, column) \n",
    "    p, a, b, mu, delta = params_hyperbolic[0], params_hyperbolic[1], params_hyperbolic[2], params_hyperbolic[3], params_hyperbolic[4]\n",
    "    p_value_hyperbolic_kstest.append(ks_2samp(norm_rvs_hyperbolic, y_data1, alternative='two-sided', method='auto')[1])\n",
    "    p_value_hyperbolic_cramervonmises.append(cramervonmises_2samp(norm_rvs_hyperbolic, y_data1, method='auto').pvalue)\n",
    "    p_value_hyperbolic_anderson.append(anderson_ksamp([norm_rvs_hyperbolic, y_data1]).significance_level)\n",
    "\n",
    "    df_hyperbolic_distribution[column] = hyperbolic_distribution\n",
    "\n",
    "\n",
    "p_value_hyperbolic = pd.DataFrame(data={'ks_test': p_value_hyperbolic_kstest, 'anderson': p_value_hyperbolic_anderson, 'cramervonmises': p_value_hyperbolic_cramervonmises},\n",
    "                    index=dataset.columns)\n",
    "\n",
    "\n",
    "\n",
    "p_value_hyperbolic.to_csv('../p_value/p_value_hyperbolic.csv', index=True)\n",
    "print(p_value_hyperbolic)\n",
    "df_hyperbolic_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stable распределение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6140/1342235073.py:11: UserWarning: p-value capped: true value larger than 0.25\n",
      "  p_value_stable_anderson.append(anderson_ksamp([norm_rvs_stable, y_data1]).significance_level)\n",
      "/tmp/ipykernel_6140/1342235073.py:11: UserWarning: p-value capped: true value larger than 0.25\n",
      "  p_value_stable_anderson.append(anderson_ksamp([norm_rvs_stable, y_data1]).significance_level)\n",
      "/tmp/ipykernel_6140/1342235073.py:11: UserWarning: p-value capped: true value larger than 0.25\n",
      "  p_value_stable_anderson.append(anderson_ksamp([norm_rvs_stable, y_data1]).significance_level)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ks_test  anderson  cramervonmises\n",
      "log_return_vkco     0.970563      0.25        0.452038\n",
      "log_return_tcs_il   0.944728      0.25        0.424119\n",
      "log_return_poly_il  0.944728      0.25        0.400373\n",
      "log_return_five_il  0.970563      0.25        0.538326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6140/1342235073.py:11: UserWarning: p-value capped: true value larger than 0.25\n",
      "  p_value_stable_anderson.append(anderson_ksamp([norm_rvs_stable, y_data1]).significance_level)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_return_vkco</th>\n",
       "      <th>log_return_tcs_il</th>\n",
       "      <th>log_return_poly_il</th>\n",
       "      <th>log_return_five_il</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.000260</td>\n",
       "      <td>0.006515</td>\n",
       "      <td>-0.000313</td>\n",
       "      <td>-0.024235</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.010546</td>\n",
       "      <td>-0.126718</td>\n",
       "      <td>0.006417</td>\n",
       "      <td>-0.008818</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.011156</td>\n",
       "      <td>0.008306</td>\n",
       "      <td>0.079715</td>\n",
       "      <td>-0.015382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.093781</td>\n",
       "      <td>0.015097</td>\n",
       "      <td>-0.000185</td>\n",
       "      <td>0.067116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.005728</td>\n",
       "      <td>-0.005820</td>\n",
       "      <td>0.011289</td>\n",
       "      <td>-0.017118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>0.007737</td>\n",
       "      <td>0.046029</td>\n",
       "      <td>0.038508</td>\n",
       "      <td>-0.015007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-0.001639</td>\n",
       "      <td>0.040559</td>\n",
       "      <td>0.040082</td>\n",
       "      <td>0.009251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>0.008643</td>\n",
       "      <td>0.020129</td>\n",
       "      <td>0.061701</td>\n",
       "      <td>0.020041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.011417</td>\n",
       "      <td>-0.022835</td>\n",
       "      <td>-0.006803</td>\n",
       "      <td>0.022554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>-0.031218</td>\n",
       "      <td>0.012725</td>\n",
       "      <td>-0.004130</td>\n",
       "      <td>-0.010840</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>252 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     log_return_vkco  log_return_tcs_il  log_return_poly_il  \\\n",
       "0          -0.000260           0.006515           -0.000313   \n",
       "1          -0.010546          -0.126718            0.006417   \n",
       "2          -0.011156           0.008306            0.079715   \n",
       "3          -0.093781           0.015097           -0.000185   \n",
       "4          -0.005728          -0.005820            0.011289   \n",
       "..               ...                ...                 ...   \n",
       "247         0.007737           0.046029            0.038508   \n",
       "248        -0.001639           0.040559            0.040082   \n",
       "249         0.008643           0.020129            0.061701   \n",
       "250         0.011417          -0.022835           -0.006803   \n",
       "251        -0.031218           0.012725           -0.004130   \n",
       "\n",
       "     log_return_five_il  \n",
       "0             -0.024235  \n",
       "1             -0.008818  \n",
       "2             -0.015382  \n",
       "3              0.067116  \n",
       "4             -0.017118  \n",
       "..                  ...  \n",
       "247           -0.015007  \n",
       "248            0.009251  \n",
       "249            0.020041  \n",
       "250            0.022554  \n",
       "251           -0.010840  \n",
       "\n",
       "[252 rows x 4 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value_stable_kstest = []\n",
    "p_value_stable_cramervonmises = []\n",
    "p_value_stable_anderson = []\n",
    "df_stable_distribution = pd.DataFrame()\n",
    "\n",
    "for column in dataset.columns:\n",
    "    params_stable, stable_distribution, y_fit_stable, norm_rvs_stable = closer_finding_functions_stable(x_data, dataset, column) \n",
    "    alpha, beta, gamma, delta = params_stable[0], params_stable[1], params_stable[2], params_stable[3],\n",
    "    p_value_stable_kstest.append(ks_2samp(norm_rvs_stable, y_data1, alternative='two-sided', method='auto')[1])\n",
    "    p_value_stable_cramervonmises.append(cramervonmises_2samp(norm_rvs_stable, y_data1, method='auto').pvalue)\n",
    "    p_value_stable_anderson.append(anderson_ksamp([norm_rvs_stable, y_data1]).significance_level)\n",
    "    \n",
    "    df_stable_distribution[column] = stable_distribution\n",
    "    \n",
    "p_value_stable = pd.DataFrame(data={'ks_test': p_value_stable_kstest, 'anderson': p_value_stable_anderson, 'cramervonmises': p_value_stable_cramervonmises},\n",
    "                    index=dataset.columns)\n",
    "\n",
    "p_value_stable.to_csv('../p_value/p_value_stable.csv', index=True)\n",
    "print(p_value_stable)\n",
    "df_stable_distribution\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Распределение Мейкснера"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6140/1881098466.py:12: UserWarning: p-value capped: true value larger than 0.25\n",
      "  p_value_meixner_anderson.append(anderson_ksamp([norm_rvs_meixner, y_data1]).significance_level)\n",
      "/tmp/ipykernel_6140/1881098466.py:12: UserWarning: p-value capped: true value larger than 0.25\n",
      "  p_value_meixner_anderson.append(anderson_ksamp([norm_rvs_meixner, y_data1]).significance_level)\n",
      "/tmp/ipykernel_6140/1881098466.py:12: UserWarning: p-value capped: true value larger than 0.25\n",
      "  p_value_meixner_anderson.append(anderson_ksamp([norm_rvs_meixner, y_data1]).significance_level)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     ks_test  anderson  cramervonmises\n",
      "log_return_vkco     0.286104      0.25        0.259682\n",
      "log_return_tcs_il   0.989103      0.25        0.674630\n",
      "log_return_poly_il  0.944728      0.25        0.405749\n",
      "log_return_five_il  0.944728      0.25        0.445311\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6140/1881098466.py:12: UserWarning: p-value capped: true value larger than 0.25\n",
      "  p_value_meixner_anderson.append(anderson_ksamp([norm_rvs_meixner, y_data1]).significance_level)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_return_vkco</th>\n",
       "      <th>log_return_tcs_il</th>\n",
       "      <th>log_return_poly_il</th>\n",
       "      <th>log_return_five_il</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.033441</td>\n",
       "      <td>0.017097</td>\n",
       "      <td>-0.010806</td>\n",
       "      <td>-0.011896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.001479</td>\n",
       "      <td>-0.013370</td>\n",
       "      <td>-0.000532</td>\n",
       "      <td>0.030908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.151054</td>\n",
       "      <td>0.029401</td>\n",
       "      <td>0.006474</td>\n",
       "      <td>-0.003548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.006785</td>\n",
       "      <td>0.010739</td>\n",
       "      <td>0.003527</td>\n",
       "      <td>-0.002355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.036155</td>\n",
       "      <td>-0.035730</td>\n",
       "      <td>-0.004105</td>\n",
       "      <td>-0.007084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>-0.002264</td>\n",
       "      <td>0.045554</td>\n",
       "      <td>0.019638</td>\n",
       "      <td>-0.019403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>249</th>\n",
       "      <td>-0.047097</td>\n",
       "      <td>-0.059285</td>\n",
       "      <td>0.003866</td>\n",
       "      <td>-0.012544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>250</th>\n",
       "      <td>0.036221</td>\n",
       "      <td>-0.038111</td>\n",
       "      <td>-0.042099</td>\n",
       "      <td>0.008905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>251</th>\n",
       "      <td>0.007415</td>\n",
       "      <td>0.045962</td>\n",
       "      <td>-0.005388</td>\n",
       "      <td>-0.005218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>252</th>\n",
       "      <td>-0.007056</td>\n",
       "      <td>0.045988</td>\n",
       "      <td>-0.002971</td>\n",
       "      <td>-0.014065</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>253 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     log_return_vkco  log_return_tcs_il  log_return_poly_il  \\\n",
       "0           0.033441           0.017097           -0.010806   \n",
       "1           0.001479          -0.013370           -0.000532   \n",
       "2          -0.151054           0.029401            0.006474   \n",
       "3          -0.006785           0.010739            0.003527   \n",
       "4           0.036155          -0.035730           -0.004105   \n",
       "..               ...                ...                 ...   \n",
       "248        -0.002264           0.045554            0.019638   \n",
       "249        -0.047097          -0.059285            0.003866   \n",
       "250         0.036221          -0.038111           -0.042099   \n",
       "251         0.007415           0.045962           -0.005388   \n",
       "252        -0.007056           0.045988           -0.002971   \n",
       "\n",
       "     log_return_five_il  \n",
       "0             -0.011896  \n",
       "1              0.030908  \n",
       "2             -0.003548  \n",
       "3             -0.002355  \n",
       "4             -0.007084  \n",
       "..                  ...  \n",
       "248           -0.019403  \n",
       "249           -0.012544  \n",
       "250            0.008905  \n",
       "251           -0.005218  \n",
       "252           -0.014065  \n",
       "\n",
       "[253 rows x 4 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_value_meixner_kstest = []\n",
    "p_value_meixner_cramervonmises = []\n",
    "p_value_meixner_anderson = []\n",
    "df_meixner_distribution = pd.DataFrame()\n",
    "\n",
    "for column in dataset.columns:\n",
    "    \n",
    "    params_meixner, meixner_distribution, y_fit_meixner, norm_rvs_meixner = closer_finding_functions_meixner(x_data, dataset, column) \n",
    "    alpha, beta, gamma, delta = params_meixner[0], params_meixner[1], params_meixner[2], params_meixner[3],\n",
    "    p_value_meixner_kstest.append(ks_2samp(norm_rvs_meixner, y_data1, alternative='two-sided', method='auto')[1])\n",
    "    p_value_meixner_cramervonmises.append(cramervonmises_2samp(norm_rvs_meixner, y_data1, method='auto').pvalue)\n",
    "    p_value_meixner_anderson.append(anderson_ksamp([norm_rvs_meixner, y_data1]).significance_level)\n",
    "    # считываем поэлементно, сохраняем в массив, добавляем массив в DataFrame\n",
    "    temp = []\n",
    "    for i in range(len(meixner_distribution)):\n",
    "        temp.append(meixner_distribution[i][0])\n",
    "    df_meixner_distribution[column] = temp\n",
    "    \n",
    "\n",
    "p_value_meixner = pd.DataFrame(data={'ks_test': p_value_meixner_kstest, 'anderson': p_value_meixner_anderson, 'cramervonmises': p_value_meixner_cramervonmises,},\n",
    "                    index=dataset.columns)\n",
    "\n",
    "p_value_meixner.to_csv('../p_value/p_value_meixner.csv', index=True)\n",
    "print(p_value_meixner)\n",
    "df_meixner_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Итого получается, что распределение Мейкснера лучше всего аппроксимирует изначальную выборку.\n",
    "Далее будем использовать dataFrame df_meixner_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[<AxesSubplot: title={'center': 'log_return_vkco'}>,\n",
       "        <AxesSubplot: title={'center': 'log_return_tcs_il'}>],\n",
       "       [<AxesSubplot: title={'center': 'log_return_poly_il'}>,\n",
       "        <AxesSubplot: title={'center': 'log_return_five_il'}>]],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_meixner_distribution.hist(bins=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_meixner_distribution.to_csv('../data/df_meixner_distribution')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
